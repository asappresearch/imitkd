generation: .

---
!Experiment

name: test-seqinter

resources:
  base_dir: /Users/alexanderlin/Desktop/empty2_seqInter
  codes_path: /Users/alexanderlin/Desktop/de-en/codes.txt
  vanilla_path: /Users/alexanderlin/Desktop/distillation/distill_nlg/de_en_other_rnns/lstm_vanilla/checkpoint/checkpoint.flambe/model
  seqKD_path: /Users/alexanderlin/Desktop/distillation/distill_nlg/de_en_other_rnns/lstm_seqKD/checkpoint/checkpoint.flambe/model
  imitKD_path: /Users/alexanderlin/Desktop/distillation/distill_nlg/de_en_other_rnns/lstm_imitKD/checkpoint/checkpoint.flambe/model

pipeline:

  # seqKD: !generation.SeqKDRunner
  #   dataset: !generation.IWSLTDataset
  #     src: 'de'
  #     tgt: 'en'
  #     year: '2014'
  #     val_frac_from_train: 0.04
  #     seed: 1234
  #     val_files: []
  #     test_files: ['dev2010', 'tst2010', 'tst2011', 'tst2012']
  #     cache: False
  #     transform:
  #       src: !TextField
  #         tokenizer: !generation.BPETokenizer
  #           codes_path: !@ codes_path
  #           nltk_tokenize_first: True
  #         lower: True
  #       tgt: !LMField
  #         tokenizer: !generation.BPETokenizer
  #           codes_path: !@ codes_path
  #           nltk_tokenize_first: True
  #         lower: True
  #         sos_token: '<SOS>'
  #         eos_token: '<EOS>'
  #   sampler: !generation.BaseSamplerWithFilter
  #     max_seq_len: 125
  #     batch_size: 128
  #     drop_last: False
  #   translator: !generation.SeqInterTranslator
  #     metric: !generation.Bleu
  #       vocab: !@ seqKD[dataset].tgt.vocab
  #       specials: ['<pad>', '<SOS>', '<EOS>']
  #     model: !generation.Seq2Seq.load_from_path
  #       path: !@ teacher
  #     tgt_sos_idx: 2
  #     tgt_eos_idx: 3
  #     max_seq_len: 126
  #     beam_size: 5
  #   base_dir: !@ base_dir
  #   train_file: 'train_file.p'
  #   val_file: 'val_file.p'
  #   test_file: 'test_file.p'
  #   others_file: 'others_file.p'
  #   use_seqinter: True
  #   split: 'train'

  train: !generation.Seq2SeqTrainer
    dataset: !generation.TensorDataset
      base_dir: !@ base_dir
      train_file: 'train_file.p'
      val_file: 'val_file.p'
      test_file: 'test_file.p'
      others_file: 'others_file.p'
      columns: ['src', 'tgt_context', 'tgt_words']
    model: !generation.Seq2Seq.load_from_path
      path: !g [!@ vanilla_path, !@ seqKD_path, !@ imitKD_path]
    translator: !generation.GreedyTranslator
      tgt_sos_idx: 2
      tgt_eos_idx: 3
      max_seq_len: 125
      sample: True
      sample_top_k: 5
    train_sampler: !generation.BaseSamplerWithFilter
      max_seq_len: 125
      batch_size: 128
      drop_last: True
    val_sampler: !generation.BaseSamplerWithFilter
      max_seq_len: 125
      batch_size: 128
      drop_last: True
    loss_fn: !torch.CrossEntropyLoss
    metric_fn: !Perplexity
    optimizer: !torch.Adam
      lr: 1e-2
      params: !@ train[model].trainable_params
    lower_is_better: True
    max_grad_norm: 5
    bleu_fn: !generation.Bleu
      vocab: !@ train[dataset].tgt_vocab
      specials: ['<pad>', '<SOS>', '<EOS>']
    batches_per_iter: 1
    iter_per_step: 1000
    iter_scheduler: !NoamScheduler
      optimizer: !@ train[optimizer]
      warmup: 2000
      d_model: 1
    max_steps: 80
    eval_translator: !generation.GreedyTranslator
      tgt_sos_idx: 2
      tgt_eos_idx: 3
      max_seq_len: 125

  eval: !Evaluator
    dataset: !generation.IWSLTDataset
      src: 'de'
      tgt: 'en'
      year: '2014'
      val_frac_from_train: 0.04
      seed: 1234
      val_files: []
      test_files: ['dev2010', 'tst2010', 'tst2011', 'tst2012']
      cache: False
      transform:
        src: !TextField
          tokenizer: !generation.BPETokenizer
            codes_path: !@ codes_path
            nltk_tokenize_first: True
          lower: True
        tgt: !TextField
          tokenizer: !generation.BPETokenizer
            codes_path: !@ codes_path
            nltk_tokenize_first: True
          lower: True
          sos_token: '<SOS>'
          eos_token: '<EOS>'
    model: !generation.BeamSearchTranslator
      model: !@ train[model]
      tgt_sos_idx: 2
      tgt_eos_idx: 3
      max_seq_len: 125
      beam_size: !g [1, 5]
    metric_fn: !generation.Bleu
      vocab: !@ eval[dataset].tgt.vocab
      specials: ['<pad>', '<SOS>', '<EOS>']
    eval_data: 'test'
    eval_sampler: !generation.BaseSamplerWithFilter
      max_seq_len: 125
      batch_size: 32
      drop_last: False
